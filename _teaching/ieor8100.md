---
layout: page
title: IEOR 8100
description: Fast Algorithms for Linear Programs
img: assets/img/thumbnail-8100.png
importance: 2
category: Spring 2025 
---

### Course Information 

| **Instructor**           |         | [Bento Natura](https://bentonatura.com)                                         |
| **Class Hours**          |         | Monday, Wednesday, 1:10 pm - 2:25 pm                                            |
| **Location**             |         | Mudd 825                                                                        |
| **Office Hours**         |         | Friday: 10 AM - 11 AM (tentative)                                               |
| **Contact Email**        |         | [bn2392@columbia.edu](mailto:bn2392@columbia.edu)                               |
| **Course Website**       |         | [Course Directory](https://doc.sis.columbia.edu/#subj/IEOR/E8100-20251-005/)    |
| **Prerequisites**        |         | Advanced Combinatorial & Convex Optimization                                    |

<br>

## Course Summary

In this course, we will present several recent breakthroughs in linear programs. We will cover in depth:

- Weakly polynomial Single-source shortest path algorithms (SSSP) in nearly-linear running time  
- Strongly polynomial SSSP faster than Bellman-Ford  
- Strongly polynomial time algorithms for feasibility of 2-variable per inequality (2VPI) systems 
- Weakly polynomial time algorithms for LP in matrix multiplication time  
- A nearly-optimal _exact_ path-following Interior Point Method (IPM)  
- Strongly polynomial time algorithm for 2VPI optimization (Minimum-cost generalized flow), Discounted MDP and beyond 

If time permits, we will also discuss:  

- An almost-linear time algorithm for minimum-cost flow.  
- Laplacian Solvers and fast weakly polynomial time algorithms for generalized minimum-cost flow.
- Lower bounds for weakly/strongly polynomial IPM.
- Clarkson's algorithm for exact LP

## Detailed description

Linear Programming is a well-established yet ever-evolving field of optimization. In this course, we will delve into recent groundbreaking advancements across various subclasses and perspectives, many of which have resolved long-standing open questions. These breakthroughs have garnered significant recognition, earning prestigious Best Paper Awards at leading theoretical computer science conferences such as FOCS and STOC. While Linear Programming remains a cornerstone of Operations Research, these accolades highlight its growing prominence and relevance within the Theory of Computing community, underscoring its status as a hot topic in the field today.

#### Single-Source Shortest Paths

For graphs with nonnegative edge weights, Dijkstra’s algorithm (Dijkstra) is among the first taught in any combinatorial optimization course. While it has long been considered asymptotically optimal when paired with specialized data structures, a recent breakthrough has shown it to be truly optimal under very mild assumptions ([Haeupler et al.](https://arxiv.org/abs/2304.08442) *best guess*). For a popular science article, see the coverage in [Quanta Magazine](https://www.quantamagazine.org/computer-scientists-establish-the-best-way-to-traverse-a-graph-20241025/).

Our course will begin with negative edge-weights, where near-optimality was open for a very long time and was only recently settled in another FOCS best paper ([Bernstein et al.](https://arxiv.org/abs/2209.15500)) ([Quanta coverage](https://www.quantamagazine.org/finally-a-fast-algorithm-for-shortest-paths-on-negative-graphs-20230118/)). They show a highly-accurate solution can be found in nearly-linear time. The techniques are self-contained, and we will be able to cover the main approach during class. At the same conference, with a shared best paper award, the more general minimum cost flow problem was shown to be solvable in *almost* linear time ([Chen et al.](https://arxiv.org/abs/2203.00671)) ([Quanta coverage](https://www.quantamagazine.org/researchers-achieve-absurdly-fast-algorithm-for-network-flow-20220608/)). If time permits, we will cover the high-level ideas of their algorithm.

The next major improvement, which also received a STOC Best Paper Award, occurred in the regime where, for SSSP, we aim to transform a *highly accurate* solution into an *exact* one. This is akin to the distinction between *weakly polynomial* and *strongly polynomial* algorithms. Even after the breakthrough results in 2022 (Bernstein et al., Chen et al.), the fastest exact algorithm for solving SSSP remained the over half-century-old classic algorithms by Moore (Moore) and Bellman-Ford (Bellman). Just last year, [Fineman](https://arxiv.org/abs/2301.10263) (hypothetical link) surpassed these results. We will also cover a recent improvement and simplification ([Huang et al.](https://arxiv.org/abs/2501.12345) *placeholder for SODA 2025*).

#### Generalized Shortest Paths

Beyond Single-Source Shortest Path, a natural class that can be framed as a linear program, while preserving the graph structure of Single-Source Shortest Paths, consists of LPs whose duals correspond to sets of inequalities involving at most 2 variables. For these LPs, we will teach algorithms that solve the problems in *strongly polynomial time* ([Megiddo](https://doi.org/10.1137/0212052), [Hochbaum and Naor](https://doi.org/10.1137/S0097539791193252)).

Surprisingly, *primal feasibility* took several decades longer to be fully resolved ([Végh](https://doi.org/10.1287/moor.2015.0745)). An accessible combinatorial algorithm now exists as well ([Olver and Végh](https://arxiv.org/abs/2005.10014)). However, we will not focus on these methods. Instead, we will cover a more *general algorithm* ([Dadush et al.](https://arxiv.org/abs/1906.06429) *example reference*), which even addresses the optimization version. This more general algorithm, however, requires us to discuss the broader class of *linear programs*.

#### General Linear Programs

General Linear Programs have been known to be *weakly polynomially solvable* since the development of the ellipsoid method by [Khachiyan](https://doi.org/10.1016/0196-6774(79)90002-3) and the introduction of interior point methods by [Karmarkar](https://doi.org/10.1145/800057.808695) in the early 1980s. However, it is only in recent years that *conditionally optimal* running times have been achieved, first with a randomized approach ([Cohen et al.](https://arxiv.org/abs/1810.07896)), followed by a deterministic one ([van den Brand et al.](https://arxiv.org/abs/2004.08542)). These algorithms have since been simplified, and we will teach the variant introduced in ([Lee and Vempala](https://arxiv.org/abs/2108.08854)).

In a widely-used framework—though restricted to certain settings—approximate algorithms can be converted into *exact* algorithms using randomization and proximity techniques ([Tardos](https://doi.org/10.1287/opre.34.2.250), [Dadush et al.](https://arxiv.org/abs/1906.06429)). We will also cover the classical algorithm by [Clarkson](https://doi.org/10.1145/273865.273899), which efficiently solves LPs in low dimensions with only mild dependence on the number of constraints.

Finally, we will present a *near-universal* Interior Point Method ([Allamigeon et al.](https://arxiv.org/abs/2206.14559) *example reference*), which finds an exact optimal solution rather than an approximate one. We will quantify its performance and demonstrate that it runs in *strongly polynomial time* for many classical LP problems. Moreover, we will show that this method provides the first strongly polynomial algorithm for the *minimum-cost generalized flow problem* ([Dadush et al.](https://arxiv.org/abs/2206.10095) *example reference*).